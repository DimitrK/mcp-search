## Architecture & Technical Feedback

### 1. **Embedding Dimension Management**

The spec mentions determining embedding dimension on first embed, but this could be problematic:

- **Issue**: Different embedding models have different dimensions (OpenAI: 1536, Cohere: 1024, etc.)
- **Suggestion**: Store the embedding model name alongside dimension in the `meta` table and validate both on startup. Consider supporting multiple embedding models simultaneously with separate tables/columns.

### 2. **Content Chunking Strategy**

The semantic chunking approach is solid, but could benefit from:

- **Addition**: Consider implementing a sliding window approach with configurable overlap percentage
- **Enhancement**: Add chunk quality scoring (based on completeness of sentences, presence of headers, etc.) to prioritize better chunks in results
- **Missing**: No mention of handling code blocks, tables, or lists specially - these often need different chunking strategies

### 3. **Rate Limiting & Backpressure**

Good that you have rate limiting, but:

- **Gap**: No mention of queue management when hitting rate limits
- **Suggestion**: Implement a priority queue for requests when under pressure, with user queries taking priority over background refreshes

### 4. **Vector Search Performance**

- **Concern**: DuckDB VSS might not scale well beyond ~100k embeddings
- **Alternative**: Consider adding an abstraction layer that allows swapping to specialized vector DBs (Qdrant, Weaviate) later without major refactoring

## Development Plan Feedback

### 5. **Milestone 1 Adjustment**

- **Add**: Include a "hello world" MCP tool implementation that actually works
- **Rationale**: This ensures the entire MCP pipeline is functional before diving into complex implementations

### 6. **Milestone 3-4 Ordering**

- **Suggestion**: Consider swapping or merging these. HTML extraction is fundamental to testing the storage layer properly
- **Alternative**: Build a simple mock content generator for Milestone 3 testing

### 7. **Missing Milestone: Observability**

Between Milestones 6 and 7, add:

- Structured logging with correlation IDs
- Performance metrics collection (even if just to logs initially)
- Request tracing through the pipeline
- This is crucial for debugging production issues

### 8. **Testing Strategy Gaps**

- **Add**: Chaos testing - randomly fail components to ensure graceful degradation
- **Add**: Load testing - concurrent requests, memory pressure scenarios
- **Add**: Contract testing between embedding provider changes

## Implementation Considerations

### 9. **Caching Strategy Enhancement**

```typescript
// Consider a multi-tier cache approach:
interface CacheStrategy {
  l1: MemoryCache; // Hot data (last hour)
  l2: DiskCache; // Warm data (last day)
  l3: DuckDB; // Cold data (persistent)
}
```

### 10. **Error Recovery Patterns**

The spec mentions degradation but could be more specific:

```typescript
// Define explicit fallback chains:
const extractionChain = [
  ReadabilityExtractor,
  CheerioExtractor,
  PlaywrightExtractor,
  RawTextExtractor // Last resort: strip HTML tags
];
```

### 11. **Security Considerations**

- **Missing**: URL validation should include checking against private IP ranges (SSRF prevention)
- **Add**: Content size limits to prevent DoS
- **Add**: Sanitization of extracted content before storage (XSS prevention if ever displayed)

### 12. **Performance Optimizations**

- **Parallel Processing**: When processing multiple queries in `readFromPage`, embed them in parallel
- **Batch Operations**: Batch DuckDB inserts/updates for better performance
- **Connection Pooling**: Not mentioned for DuckDB - important for concurrent requests

## Risk Mitigation

### 13. **DuckDB File Locking**

- **Risk**: DuckDB uses file-based locking which could cause issues with multiple processes
- **Mitigation**: Implement a connection pool with proper transaction management

### 14. **Playwright Memory Leaks**

- **Risk**: Playwright can leak memory if not properly closed
- **Mitigation**: Implement a worker pool with automatic recycling after N requests

### 15. **Embedding Provider Failures**

- **Enhancement**: Cache embedding provider health status to avoid repeated failing requests
- **Add**: Implement circuit breaker pattern with exponential backoff

## Additional Suggestions

### 16. **Development Tooling**

```json
<code_block_to_apply_changes_from>
```

### 17. **Configuration Management**

Consider using a schema-validated config file in addition to env vars:

```typescript
// config.schema.ts
const ConfigSchema = z.object({
  embeddings: z.object({
    provider: z.enum(['openai', 'cohere', 'local']),
    batchSize: z.number().default(32),
    maxRetries: z.number().default(3)
  })
  // ... more config
});
```

### 18. **Monitoring Readiness**

Even though "no metrics in MVP", add hooks for future monitoring:

```typescript
interface MetricsCollector {
  increment(metric: string): void;
  timing(metric: string, duration: number): void;
  gauge(metric: string, value: number): void;
}
// Start with no-op implementation, easy to swap later
```

## Timeline Adjustments

Your timeline seems optimistic for TDD approach. Consider:

- **Milestone 1**: 2-3 days → **3-4 days** (MCP setup can be tricky)
- **Milestone 5**: 4-5 days → **6-7 days** (embedding integration often has surprises)
- **Add buffer**: 5-7 days total for integration issues and refactoring

## Priority Recommendations

If timeline becomes tight, prioritize:

1. **Core functionality** over optimizations
2. **Error handling** over performance
3. **Testing** over documentation (docs can be added post-MVP)
4. **Single embedding provider** initially (skip provider abstraction)

The overall plan is solid and well-thought-out. The TDD approach and incremental milestones are excellent choices. Main suggestion is to build in more flexibility around the vector storage and embedding layers to ease future scaling.
